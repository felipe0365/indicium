# -*- coding: utf-8 -*-
"""indicium_imdb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pqJbYUHxjpgEP1E-p3c60GG1yAnvKH0H
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

sns.set_style("whitegrid")
plt.rcParams["figure.figsize"] = (12, 6)
plt.rcParams["font.size"] = 12

df = pd.read_csv("desafio_indicium_imdb.csv")

df.info()

df["Runtime"] = df["Runtime"].str.replace(" min", "").astype(int)
df["Gross"] = df["Gross"].str.replace(",","").astype(float)

df.info()

print(df.isnull().sum())

"""---

# **Tratamento da coluna "Certificate
"""

df['Certificate'].fillna('Not Rated', inplace=True)

"""---
# **Tratamento da coluna "Meta_score"**
"""

plt.figure(figsize=(10, 5))
sns.histplot(df['Meta_score'].dropna(), kde=True, color='purple')
plt.title('DistribuiÃ§Ã£o do Meta_score')
plt.show()

meta_mean = df['Meta_score'].mean()
meta_median = df['Meta_score'].median()
print(f"MÃ©dia do Meta_score: {meta_mean:.2f}")
print(f"Mediana do Meta_score: {meta_median:.2f}")

df['Meta_score'].fillna(meta_median, inplace=True)

"""---

# **Tratamento da coluna "Meta_score"**
"""

plt.figure(figsize=(10, 5))
sns.histplot(df['Gross'].dropna(), kde=True, color='green', log_scale=True)
plt.title('DistribuiÃ§Ã£o do Faturamento Bruto (Gross) - Escala de Log')
plt.show()

gross_mean = df['Gross'].mean()
gross_median = df['Gross'].median()
print(f"MÃ©dia do Faturamento: ${gross_mean:,.2f}")
print(f"Mediana do Faturamento: ${gross_median:,.2f}")

df['Gross'].fillna(gross_median, inplace=True)

print(df.isnull().sum())

df.info()

"""---

# **Tratando coluna "Released_Year"**
"""

df.loc[df['Series_Title'] == 'Apollo 13', 'Released_Year'] = 1995

df['Released_Year'] = df['Released_Year'].astype(int)

df.info()

"""---

# **1. AnÃ¡lise ExploratÃ³ria**

**AnÃ¡lise de faturamento por gÃªnero**

**LÃ­deres de Bilheteria:** GÃªneros como Aventura, Sci-Fi e AÃ§Ã£o dominam o topo da lista, apresentando o maior faturamento mediano. Isso confirma que filmes de grande espetÃ¡culo visual sÃ£o os principais motores da indÃºstria cinematogrÃ¡fica em termos de receita.
"""

df_genres = df.copy()
df_genres['Genre'] = df_genres['Genre'].str.split(', ')
df_exploded = df_genres.explode('Genre')

median_gross_by_genre = df_exploded.groupby('Genre')['Gross'].median().sort_values(ascending=False)

plt.figure(figsize=(15, 8))
sns.boxplot(data=df_exploded, x='Gross', y='Genre', order=median_gross_by_genre.index, palette='magma_r', showfliers=False)
plt.title('DistribuiÃ§Ã£o do Faturamento Bruto por GÃªnero (Mediana)')
plt.xlabel('Faturamento Bruto (Gross) - Excluindo Outliers para VisualizaÃ§Ã£o')
plt.ylabel('GÃªnero')
plt.xscale('log') # Escala de log Ã© Ã³tima para dados de faturamento
plt.show()

print("Top 5 GÃªneros por Faturamento Mediano:")
print(median_gross_by_genre.head())

"""---

**AnÃ¡lise Temporal**

**DuraÃ§Ã£o MÃ©dia (Runtime):** HÃ¡ uma tendÃªncia de aumento na duraÃ§Ã£o dos filmes a partir dos anos 1990. Isso pode significar uma maior disposiÃ§Ã£o do pÃºblico para narrativas mais longas e complexas, ou uma tendÃªncia dos diretores em criar filmes mais imersivos.

**Faturamento e Votos (Gross, No_of_Votes):** Essas mÃ©tricas explodem a partir dos anos 60. Isso nÃ£o significa necessariamente que os filmes mais novos sÃ£o "melhores", mas sim o crescimento do mercado de cinema global e, principalmente, a ascensÃ£o da internet, que tornou a votaÃ§Ã£o e o engajamento do pÃºblico massivos e instantÃ¢neos.

**Nota MÃ©dia (IMDB_Rating):** A nota mÃ©dia parece ter picos em certas "eras de ouro", como os anos 1950 e 2010. Isso pode indicar perÃ­odos de grande inovaÃ§Ã£o no cinema.
"""

df['Decade'] = (df['Released_Year'].astype(int) // 10) * 10

decade_analysis = df.groupby('Decade').agg({
    'IMDB_Rating': 'mean',
    'Runtime': 'mean',
    'Gross': 'mean',
    'No_of_Votes': 'mean'
}).reset_index()

fig, axes = plt.subplots(2, 2, figsize=(16, 10))
fig.suptitle('TendÃªncias CinematogrÃ¡ficas ao Longo das DÃ©cadas', fontsize=16)

sns.lineplot(ax=axes[0, 0], data=decade_analysis, x='Decade', y='IMDB_Rating', marker='o')
axes[0, 0].set_title('MÃ©dia da Nota IMDB')

sns.lineplot(ax=axes[0, 1], data=decade_analysis, x='Decade', y='Runtime', marker='o', color='red')
axes[0, 1].set_title('DuraÃ§Ã£o MÃ©dia (minutos)')

sns.lineplot(ax=axes[1, 0], data=decade_analysis, x='Decade', y='Gross', marker='o', color='green')
axes[1, 0].set_title('Faturamento MÃ©dio')

sns.lineplot(ax=axes[1, 1], data=decade_analysis, x='Decade', y='No_of_Votes', marker='o', color='purple')
axes[1, 1].set_title('NÃºmero MÃ©dio de Votos')

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""---

# **2. Perguntas**

---

**a. Qual filme vocÃª recomendaria para uma pessoa que vocÃª nÃ£o conhece?**
- Recomendaria um filme com a maior probabilidade de agradar essa pessoa. Ou seja, um filme que tenha uma alta avaliaÃ§Ã£o do pÃºblico, alto nÃºmero de votos.
- Ou recomendaria os melhores filmes de cada gÃªnero.
"""

recommendation = df.sort_values(by=['IMDB_Rating', 'No_of_Votes'], ascending=[False, False]).iloc[0]

print("O filme recomendado:")
print(f"TÃ­tulo: {recommendation['Series_Title']} ({recommendation['Released_Year']})")
print(f"GÃªnero: {recommendation['Genre']}")

print(f"Nota IMDB: {recommendation['IMDB_Rating']} de 10 (a mais alta do dataset).")
print(f"NÃºmero de Votos: {int(recommendation['No_of_Votes']):,} (uma das maiores votaÃ§Ãµes.")

def get_top_movie_for_genre(genre_name, dataframe):
    genre_df = dataframe[dataframe['Genre'] == genre_name]

    top_movie = genre_df.sort_values(by=['IMDB_Rating', 'No_of_Votes'], ascending=[False, False]).iloc[0]

    return top_movie

genres_to_recommend = ['Drama', 'Action', 'Sci-Fi', 'Crime', "Romance", "Crime", "Music", "Animation", "Biography", "Family"]

for genre in genres_to_recommend:
    movie = get_top_movie_for_genre(genre, df_exploded)

    print(f"ðŸŽ¬ Para quem gosta de '{genre}':")
    print(f"   - TÃ­tulo: {movie['Series_Title']} ({int(movie['Released_Year'])})")
    print(f"   - Nota IMDB: {movie['IMDB_Rating']}/10.0")
    print(f"   - Sinopse: {movie['Overview']}")
    print("-" * 40)

"""---

b. **Quais sÃ£o os principais fatores que estÃ£o relacionados com alta expectativa de faturamento de um filme?**
- NÃºmero de votos ("No_of_Votes")
- Ano de lanÃ§amento ("Released_Year")
- AvaliaÃ§Ã£o do IMDB ("IMDB_Rating)
"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RandomizedSearchCV

param_grid = {
    'n_estimators': [100, 200, 300, 500],
    'max_depth': [10, 20, 30, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2']
}

features = ['Released_Year', 'Runtime', 'IMDB_Rating', 'Meta_score', 'No_of_Votes', ]
target = 'Gross'

X = df[features]
y = df[target]

rf_model = RandomForestRegressor(random_state=42)

random_search = RandomizedSearchCV(
    estimator=rf_model,
    param_distributions=param_grid,
    n_iter=50,
    cv=5,
    scoring='neg_mean_squared_error',
    verbose=1,
    random_state=42,
    n_jobs=-1
)

random_search.fit(X, y)

print("Melhores parÃ¢metros encontrados:")
print(random_search.best_params_)

best_score_rmse = np.sqrt(-random_search.best_score_)
print(f"\nMelhor performance mÃ©dia (RMSE) com validaÃ§Ã£o cruzada: ${best_score_rmse:,.2f}")

final_model = RandomForestRegressor(**random_search.best_params_, random_state=42)

final_model.fit(X, y)

feature_importances = pd.Series(final_model.feature_importances_, index=features).sort_values(ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x=feature_importances, y=feature_importances.index, palette='inferno')
plt.title('Principais Fatores para o Faturamento (Gross)')
plt.xlabel('ImportÃ¢ncia')
plt.ylabel('Feature')
plt.show()

"""---

c. **Quais insights podem ser tirados com a coluna Overview? Ã‰ possÃ­vel inferir o gÃªnero do filme a partir dessa coluna?**
- Sim, Ã© possÃ­vel. Com a coluna Overview, podemos fazer uma nuvem de palavras com os termos mais frequentes de cada gÃªnero
"""

from wordcloud import WordCloud

genre = "Music"
sci_fi_text = " ".join(overview for overview in df_exploded[df_exploded['Genre'] == genre]['Overview'])

wordcloud = WordCloud(background_color="black", collocations=False, width=800, height=400).generate(sci_fi_text)

plt.figure(figsize=(15, 7))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.title(f"Nuvem de Palavras para o GÃªnero: {genre}", fontsize=20)
plt.show()

"""---


# **3. Perguntas Nota IMDB**
**a. Explique como vocÃª faria a previsÃ£o da nota do imdb a partir dos dados.**
- Primeiramente, eu prepararia e limparia os dados, verificando a existencia de dados nulos e transformando algumas colunas para nÃºmeros
- Definiria as colunas que seriam usadas como as "Features" e o "Target"
- Separaria os dados em dados de teste e treinamento
- Treinaria o modelo usando algum algoritmo de machine learning
- Realizaria a prediÃ§Ã£o usando o modelo treinado
- Caso necessÃ¡rio, faria mudanÃ§a em alguns hiperparametros para melhorar a performace do modelo

b. **Quais variÃ¡veis e/ou suas transformaÃ§Ãµes vocÃª utilizou e por quÃª?**
- Utilizei como variavel: Runtime, Meta_score, No_of_Votes, Gross, Movie_age, Main_Genre e Director
- Fiz transformaÃ§Ãµes em Runtime e Gross, removendo os textos contidos neste dado e converti para nÃºmero, pois modelos matematicos nÃ£o conseguem textos misturados sÃ³ numeros.
- Criei o Movie_age, porque Ã© uma feature mais intuitiva do que Realease_Year
- Crei o Main_Genre para dar uma simplificada para o modelo e deixar mais direta e facil dele aprender
- Utilizei a tÃ©cnica One-Hot Enconding em Main_Genre e Director, pois o modelo nÃ£o entende texto, entÃ£o essa tÃ©cnica converte cada categoria para valores nÃºmericos

**c. Qual tipo de problema estamos resolvendo (regressÃ£o, classificaÃ§Ã£o)?**
- Estamos resolvendo um problema de regressÃ£o, pois prever o IMDB_Rating Ã© um valor nÃºmerico e contÃ­nuo, logo, Ã© um problema de regressÃ£o.

**d. Qual modelo melhor se aproxima dos dados e quais seus prÃ³s e contras?**-
- Utilizei o modelo XGBoost Regressor, pois Ã© um modelo bom para trabalhar com dados tabulares.

**e. Qual medida de performance do modelo foi escolhida e por quÃª?**
- Utilizei o RMSE, pois o resultado estÃ¡ na mesma unidade da nota do IMDB, o RMSE diz, em mÃ©dia, quantos pontos o modelo erra em suas previsÃµes. Ex: 0.1 significa que o modelo esta errando na mÃ©dia de 0.1 pontos.
- O RMSE penaliza os maiores erros, ou seja, caso haja um erro muito grande, ele serÃ¡ penalizado muito mais que um erro pequeno. Ele faz isso calculando a diferenÃ§a entre as previsÃµes e os valores reais e elevando ao quadrado.

---


# **4. PrevisÃ£o Nota IMDB**
- A previsÃ£o da nota para o novo filme Ã© 8.96.
- Primeiramente, foi feito um treinamento no modelo sem a utilizaÃ§Ã£o da biblioteca SHAP, porÃ©m, utilizei a biblioteca e percebi que o modelo estava com o problema de Overfitting por Alta Cardinaliade. A coluna "Director" tinha muitos valores Ãºnicos (vÃ¡rios diretores diferentes). Ao aplicar o One-Hot Encoding, foi criado centenas de novas colunas para cada diretor. Como muitos diretores sÃ³ tinham 1 filme, o modelo memorizou: "Se uma coluna de direto Ã© 1, a nota Ã© X", ou seja, isso causaria problemas com um novo filme de um diretor que ele nunca tinha visto antes.

# **SoluÃ§Ã£o**
- Identifiquei os diretores que mais apareciam, manti as colunas individuais deles e agrupei os outros diretores que apareciam menos em outra categoria.
- Isso faz o modelo aprender padrÃµes mais gerais, pois reduzi bastante o nÃºmero de colunas.
"""

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
import xgboost as xgb
from sklearn.metrics import mean_squared_error

current_year = 2025
df['Movie_Age'] = current_year - df['Released_Year']

df['Main_Genre'] = df['Genre'].apply(lambda x: x.split(',')[0])

numerical_features = ['Runtime', 'Meta_score', 'No_of_Votes', 'Gross', 'Movie_Age']
categorical_features = ['Main_Genre', 'Director']

features = numerical_features + categorical_features
target = 'IMDB_Rating'

X = df[numerical_features + categorical_features]
y = df['IMDB_Rating']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

preprocessor = ColumnTransformer(
    transformers=[
        ('num', 'passthrough', numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])

model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42))
])

model_pipeline.fit(X_train, y_train)

predictions = model_pipeline.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, predictions))
print(f"A performance quantitativa do modelo (RMSE): {rmse:.4f}")

import shap

X_test_transformed = model_pipeline.named_steps['preprocessor'].transform(X_test)
feature_names_transformed = numerical_features + \
    model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features).tolist()

X_test_transformed_df = pd.DataFrame(X_test_transformed.toarray(), columns=feature_names_transformed)

explainer = shap.TreeExplainer(model_pipeline.named_steps['regressor'])
shap_values = explainer.shap_values(X_test_transformed_df)

shap.summary_plot(shap_values, X_test_transformed_df, plot_type="bar", show=False)
plt.title("ImportÃ¢ncia Global das Features (SHAP)")
plt.show()

shap.summary_plot(shap_values, X_test_transformed_df, show=False)
plt.title("Impacto das Features nas PrevisÃµes do Modelo (SHAP)")
plt.show()

top_directors = df['Director'].value_counts().nlargest(15).index

df['Director_simplified'] = df['Director'].apply(lambda x: x if x in top_directors else 'Other')

print("Diretores que serÃ£o tratados como categorias individuais:")
print(top_directors.tolist())

categorical_features = ['Main_Genre', 'Director_simplified']

X = df[numerical_features + categorical_features]
y = df['IMDB_Rating']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

preprocessor = ColumnTransformer(
    transformers=[
        ('num', 'passthrough', numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])

model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42))
])

model_pipeline.fit(X_train, y_train)

predictions = model_pipeline.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, predictions))
print(f"A performance quantitativa do modelo (RMSE): {rmse:.4f}")

X_test_transformed = model_pipeline.named_steps['preprocessor'].transform(X_test)
feature_names_transformed = numerical_features + \
    model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features).tolist()

X_test_transformed_df = pd.DataFrame(X_test_transformed.toarray(), columns=feature_names_transformed)

explainer = shap.TreeExplainer(model_pipeline.named_steps['regressor'])
shap_values = explainer.shap_values(X_test_transformed_df)

shap.summary_plot(shap_values, X_test_transformed_df, plot_type="bar", show=False)
plt.title("ImportÃ¢ncia Global das Features (SHAP)")
plt.show()

shap.summary_plot(shap_values, X_test_transformed_df, show=False)
plt.title("Impacto das Features nas PrevisÃµes do Modelo (SHAP)")
plt.show()

new_movie_data = {
    'Series_Title': 'The Shawshank Redemption',
    'Released_Year': '1994',
    'Certificate': 'A',
    'Runtime': '142 min',
    'Genre': 'Drama',
    'Overview': 'Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.',
    'Meta_score': 80.0,
    'Director': 'Frank Darabont',
    'Star1': 'Tim Robbins',
    'Star2': 'Morgan Freeman',
    'Star3': 'Bob Gunton',
    'Star4': 'William Sadler',
    'No_of_Votes': 2343110,
    'Gross': '28,341,469'
}

new_movie_df = pd.DataFrame([new_movie_data])

new_movie_df.head()

new_movie_df['Runtime'] = new_movie_df['Runtime'].str.replace(' min', '').astype(int)
new_movie_df['Gross'] = new_movie_df['Gross'].str.replace(',', '').astype(float)
new_movie_df['Released_Year'] = new_movie_df['Released_Year'].astype(int)
new_movie_df['Movie_Age'] = current_year - new_movie_df['Released_Year']
new_movie_df['Main_Genre'] = new_movie_df['Genre'].apply(lambda x: x.split(',')[0])

new_movie_df[features].head()

top_directors = df['Director'].value_counts().nlargest(15).index
new_movie_df['Director_simplified'] = new_movie_df['Director'].apply(lambda x: x if x in top_directors else 'Other')

predicted_rating = model_pipeline.predict(new_movie_df)
final_prediction = predicted_rating[0]

print(f"A nota IMDB PREVISTA para 'The Shawshank Redemption' Ã©:")
print(f" >> {final_prediction:.2f} << ")

"""

---

# **Salvando o modelo**"""

import pickle

filename = 'imdb_rating_predictor.pkl'

with open(filename, 'wb') as file:
    pickle.dump(model_pipeline, file)